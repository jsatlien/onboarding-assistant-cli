# Onboarding Assistant CLI

A command-line tool for generating and uploading metadata for the Onboarding Assistant. This tool simplifies the process of extracting contextual metadata from your application's source code and uploading it as embeddings to OpenAI for use with a Retrieval Augmented Generation (RAG) assistant.

## Installation

You can install the package globally:

```bash
npm install -g onboarding-assistant-cli
```

Or run it directly using npx:

```bash
npx onboarding-assistant-cli
```

## Prerequisites

- Node.js 14+
- OpenAI API key and Assistant ID (for embedding upload)

**Note**: Python 3.6+ is only required for the legacy commands. The new recommended commands (`generate-frontend-context` and `generate-backend-context`) are pure JavaScript and do not require Python.

## Configuration

The tool requires a YAML configuration file with your OpenAI credentials and settings. You can create this file automatically using the `init` command, or manually create it at `./config/assistant_config.yaml`:

```yaml
# OpenAI API credentials
openai_api_key: "sk-your-api-key-here"  # Replace with your actual OpenAI API key
assistant_id: "asst_your-assistant-id-here"  # Replace with your OpenAI Assistant ID

# Embedding model to use
embedding_model: "text-embedding-3-small"

# Paths for metadata and embeddings
metadata_path: "./output"  # Path to the metadata files generated by metadata_generator.py
index_path: "./output/embeddings.json"  # Path where embeddings will be stored

# Format for embeddings (currently only OpenAI is supported)
embedding_format: "openai"  # Future: pinecone, weaviate
```

> ‚ö†Ô∏è **SECURITY WARNING**: This file contains your OpenAI API key. Make sure to add `config/assistant_config.yaml` to your `.gitignore` file to prevent accidentally committing sensitive credentials to your repository.

## Commands

### New Commands (Recommended)

#### Generate Frontend Context

Generate embedding-ready context files from your frontend source code:

```bash
npx onboarding-assistant generate-frontend-context
```

This interactive command will:
- Prompt you to select your frontend framework (currently supports Vue)
- Ask for the path to your source files
- Ask for the output directory
- Process all Vue files, extracting routes from router configuration when possible
- Output each file as a .txt file in the output/routes/ directory with appropriate headers

#### Generate Backend Context

Generate embedding-ready context files from your backend model files:

```bash
npx onboarding-assistant generate-backend-context
```

This interactive command will:
- Prompt you to select your ORM (currently supports Entity Framework)
- Ask for the path to your model files
- Ask for the output directory
- Process all model files, detecting Entity Framework models
- Output each model as a .txt file in the output/models/ directory with appropriate headers

### Legacy Commands

> **Note**: The following commands use the older metadata-based approach and require Python. The new commands above are recommended instead.

#### Initialize Configuration

Set up your OpenAI API key and Assistant ID:

```bash
npx onboarding-assistant init
```

This will:
- Create necessary directories
- Prompt for your OpenAI API key and Assistant ID
- Generate a configuration file

#### Extract Metadata

Extract metadata from your source code:

```bash
npx onboarding-assistant extract <source-dir> --output-dir ./output
```

Options:
- `<source-dir>`: Directory containing your source code (required)
- `--output-dir`, `-o`: Directory where metadata will be saved (default: "./output")

#### Upload Embeddings

Upload embeddings to OpenAI:

```bash
npx onboarding-assistant upload --config ./config/assistant_config.yaml
```

Options:
- `--config`, `-c`: Path to configuration file (default: "./config/assistant_config.yaml")
- `--force`, `-f`: Force processing of all files, even if unchanged
- `--verbose`, `-v`: Print verbose output
- `--quiet`, `-q`: Suppress progress bar and non-error output

#### All-in-One Workflow

Run the complete workflow (extract metadata and upload embeddings):

```bash
npx onboarding-assistant all <source-dir> --output-dir ./output --config ./config/assistant_config.yaml
```

This combines the extract and upload commands in one step.

## Complete Workflow

### Recommended Workflow (New)

Here's the recommended workflow for setting up and using the Onboarding Assistant:

1. **Set up an OpenAI Assistant**
   - Create an OpenAI account and get an API key
   - Create a new Assistant with appropriate instructions (see [OpenAI Assistant Setup](#openai-assistant-setup))
   - Copy the Assistant ID

2. **Generate frontend context**
   - Run `npx onboarding-assistant generate-frontend-context`
   - Follow the prompts to select your frontend framework and paths
   - This generates .txt files with the full source code of your frontend components

3. **Generate backend context (if applicable)**
   - Run `npx onboarding-assistant generate-backend-context`
   - Follow the prompts to select your ORM and paths
   - This generates .txt files with the full source code of your backend models

4. **Upload the generated .txt files to your OpenAI Assistant**
   - Go to your Assistant in the OpenAI platform
   - Upload the generated .txt files from the output/routes/ and output/models/ directories
   - These files will be used as context for your Assistant

5. **Integrate the Onboarding Assistant into your application**
   - Follow the integration instructions in the [main project documentation](https://github.com/jsatlien/onboarding-assistant)

### Legacy Workflow

The legacy workflow using metadata extraction and Python:

1. **Set up an OpenAI Assistant**
   - Create an OpenAI account and get an API key
   - Create a new Assistant with appropriate instructions
   - Copy the Assistant ID

2. **Configure the tools**
   - Run `npx onboarding-assistant init` to create the configuration file
   - Or manually create/update `config/assistant_config.yaml` with your API key and Assistant ID

3. **Extract metadata from your application**
   - Run `npx onboarding-assistant extract <source_dir> --output-dir ./output`
   - This generates JSON files with contextual information about your app

4. **Generate and upload embeddings**
   - Run `npx onboarding-assistant upload --config ./config/assistant_config.yaml`
   - This creates embeddings for each route and stores them locally

## How It Works

### New Approach (Recommended)

The new commands use a direct source-to-text approach:

1. **Scan your source code files**
   - Recursively finds all Vue files or C# model files in the specified directory
   - For Vue files, attempts to extract routes from router configuration files
   - For C# files, identifies Entity Framework models using common patterns

2. **Generate context files**
   - Creates .txt files with the full source code of each file
   - Adds minimal header comments with file path and route/model information
   - Preserves original formatting and indentation

3. **Output organized files**
   - Frontend files are saved to output/routes/ with kebab-case filenames
   - Backend files are saved to output/models/ with kebab-case filenames
   - Files are ready to be uploaded directly to your OpenAI Assistant

### Legacy Approach

The legacy commands use Python scripts that:

1. **Scan your source code to extract contextual metadata**
   - Analyzes various file types (.vue, .cs, .json, etc.)
   - Extracts routes, UI elements, API calls, and user actions
   - Generates structured JSON metadata files

2. **Format the metadata for embedding**
   - Converts structured JSON into flat text blocks optimized for embedding
   - Prepares the content for the OpenAI Embedding API

3. **Upload the embeddings to OpenAI**
   - Uses the OpenAI API to generate vector embeddings
   - Tracks file changes to avoid reprocessing unchanged files
   - Handles errors with retries and exponential backoff

4. **Store the results for use with the Onboarding Assistant**
   - Saves embeddings to a local JSON file
   - Maintains file hashes to track changes
   - Prepares the data for retrieval by your assistant

## Output Format

The metadata generator produces JSON files with the following structure:

```json
{
  "route": "/dashboard",
  "description": "Main dashboard displaying widgets.",
  "elements": [
    {"id": "widget-list", "description": "List of user widgets"},
    {"id": "refresh-button", "description": "Refresh data"}
  ],
  "apiCalls": ["/api/dashboard"],
  "dependencies": ["WidgetComponent", "ChartComponent"],
  "userActions": ["View widgets", "Refresh data"]
}
```

The embedding tool generates two output files:

1. **embeddings.json**: Contains the embeddings for each route

```json
{
  "/route": {
    "embedding": [0.123, 0.456, ...],
    "text": "ROUTE: /route\n\nDESCRIPTION: ..."
  }
}
```

2. **hashes.json**: Tracks file hashes to avoid reprocessing unchanged files

## Framework Compatibility

The metadata generator is designed to work with various frontend frameworks, with different levels of support:

- **Vue.js**: Optimized support with detailed extraction of components, props, and Vue-specific patterns
- **React**: Basic support for component extraction and JSX parsing
- **Angular**: Basic support for component and template extraction
- **Plain HTML/JS**: Can extract elements with IDs and comments
- **.NET/C#**: Extracts API routes and controller actions from backend code

While the tool works best with Vue.js applications, it will still extract useful metadata from other frameworks.

## OpenAI Assistant Setup

Before extracting and uploading metadata, you need to set up an OpenAI Assistant to use with the Onboarding Assistant.

### Step 1: Set Up Your OpenAI Account

1. Visit https://platform.openai.com/ and sign in.
2. Go to https://platform.openai.com/api-keys.
3. Click "Create new secret key" and copy it.
4. Store this key securely ‚Äî you'll add it to your config file using the `init` command.

### Step 2: Manually Create an Assistant

Navigate to https://platform.openai.com/assistants.

Click "Create Assistant".

Fill out the fields as described below.

#### Assistant Configuration

| Field | What to Enter |
| ----- | ------------- |
| Name | Any friendly name for your assistant (e.g., Walli, Repair Assistant) |
| Instructions | Paste in the Assistant Instructions Template from below and fill in the variables |
| Model | See model guidance below |
| Tools | See tool guidance below |

#### Model Selection

| Model | Cost | Context Length | Notes |
| ----- | ---- | -------------- | ----- |
| gpt-4o (recommended) | üí∞üí∞ | 128k tokens | Best speed + price/performance ratio. Great for production use. |
| gpt-4-turbo | üí∞üí∞üí∞ | 128k tokens | Similar to gpt-4o, slightly slower, formerly the best option. |
| gpt-3.5-turbo | üí∞ | 16k tokens | Budget-friendly, less accurate with instructions and metadata. |

‚úÖ Recommendation: Use gpt-4o for the best balance of cost, speed, and understanding.

#### Tool Selection

‚úÖ **File Search (RECOMMENDED ‚Äì Enable)**
- Allows the assistant to retrieve answers from attached files.
- In the future, you may upload your metadata or configuration files here.
- For now, it can be left unused, but enable it to future-proof your setup.

‚ùå **Code Interpreter (DISABLE)**
- Used for writing and executing Python code inside the assistant.
- Not needed for this implementation.

‚ùå **Functions (DISABLE)**
- Enables the assistant to call external APIs or frontend functions.
- Leave it disabled for now. You can add this later if you build out the frontend bridge.

#### Assistant Instructions Template

```
You are {{ASSISTANT_NAME}}, a contextual onboarding assistant for a web application called {{APP_NAME}}, which operates in the {{APP_DOMAIN}} domain.

Your job is to help users:
- Understand what each page of the app does
- Find and interact with relevant UI elements on the current screen
- Navigate through the application as needed

You receive metadata from the developer that includes:
- The current route (e.g. "/workorders/new")
- A description of what the page does
- A list of UI elements with their labels or IDs
- Any associated API calls or user actions

Use this information to answer user questions clearly and concisely. Highlight UI elements when needed. Do not make assumptions about application internals beyond the provided metadata.

If users ask for your name or what to call you, tell them you are {{ASSISTANT_NAME}}.

Remain friendly, professional, and grounded in the current page context at all times.
```

> ‚ö†Ô∏è **Important**: Replace `{{APP_NAME}}` and `{{APP_DOMAIN}}` with your actual app name and domain/industry. Replace `{{ASSISTANT_NAME}}` with a friendly name for your assistant (e.g., "Riley", "Fixie").

### Step 3: Copy the Assistant ID

Once the assistant is saved, you'll see an ID like:

```
asst_abc123456789
```

You'll need this ID when running the `init` command or adding it to your config file.

## Troubleshooting

If you encounter issues:

- Make sure Python 3.6+ is installed and in your PATH
- Check that your OpenAI API key and Assistant ID are correct
- Ensure your source directory contains valid code files
- Verify that the config file exists and has the correct format
- Try running with the `--verbose` flag for more detailed output
- Check for error logs in the `logs` directory

For more detailed information, see the [Onboarding Assistant documentation](https://github.com/jsatlien/onboarding-assistant).
